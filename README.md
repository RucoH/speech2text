# ğŸ™ï¸ speech2text

## ğŸ“˜ Project Description

**speech2text** is a flexible toolkit for **offline** and **real-time (streaming) speech-to-text (STT) conversion** with multi-model support. It offers:
- Local audio recording utilities
- Benchmarking for latency, memory usage, and accuracy (WER/CER)
- Easy integration of multiple STT models
- Multilingual transcription (focus on Turkish and English)

## âœ¨ Features

* ğŸ™ï¸ Offline and streaming transcription
* ğŸ“ Benchmarking: latency, memory, accuracy
* ğŸšï¸ Compare multiple models side-by-side
* ğŸ—‚ï¸ Local audio capture and management
* ğŸŒ Multilingual support (Turkish, English, more)

## âš™ï¸ Installation

Clone the repository:
```bash
git clone https://github.com/RucoH/speech2text.git
cd speech2text
```

Create a virtual environment and install dependencies:
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Mac/Linux
source .venv/bin/activate

pip install --upgrade pip
pip install -r requirements.txt
```

> **Note:** Install `ffmpeg` and ensure your PyTorch installation matches your hardware (GPU/CPU).

## ğŸš€ Usage

### ğŸ¤ Record Audio from Microphone
```bash
python record_voice.py \
  --out data/demo.wav \
  --seconds 15 \
  --rate 16000
```

### ğŸ” Transcribe Audio (example)
```bash
python src/fasterwhisper_test.py \
  --model large-v3 \
  --audio data/demo.wav \
  --language tr \
  --compute-type float16
```

## ğŸ§  Supported Models

* **Faster-Whisper** (CTranslate2, CPU/GPU)
* **OpenAI Whisper** (Large/Medium/Small)
* **SeamlessM4T-v2** (Meta multilingual)
* **Wav2Vec2** (e.g., `facebook/wav2vec2-large-xlsr-53`)
* **MMS-1B-ALL** (Meta multilingual speech)
* **Vosk** (lightweight, local)
* **Silero STT** (lightweight, local)
* ~~Deepspeech / Coqui-STT~~ (archived/no longer maintained)

## ğŸ—‚ï¸ Project Structure
```
speech2text/
â”œâ”€â”€ data/                     # Sample input/output audio and transcripts
â”œâ”€â”€ model_checkpoints/        # (Optional) Local model weights/cache
â”‚   â””â”€â”€ models--facebook--wav2vec2-large-xlsr-53/
â”œâ”€â”€ models/                   # Model wrappers/adapters (if any)
â”œâ”€â”€ src/                      # Executable scripts and helper modules
â”œâ”€â”€ record_voice.py           # Quick audio recording script
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ LICENSE                   # MIT License
â””â”€â”€ README.md                 # This file
```

## ğŸ›  Troubleshooting

* **CUDA not found / slow performance:** Verify driver and CUDA compatibility.
* **FFmpeg missing:** Check with `ffmpeg -version` and install if missing.
* **Long recordings cut off:** Increase segment length and enable `vad`.

## ğŸ—º Roadmap

- [ ] **Streaming ASR example:** Implement microphone â†’ live transcript pipeline.
- [ ] **YouTube audio ingestion:** Download and transcribe directly from YouTube URLs.
- [ ] **Web interface:** Add Gradio or similar web UI for easy interaction.
- [ ] **VAD & diarization:** Integrate voice activity detection and speaker separation.
- [ ] **Benchmark dashboard:** Visualize latency, memory, and WER results.
- [ ] **Language expansion:** Add support for more languages and accents.
- [ ] **Deployment options:** Docker, Hugging Face Spaces, and cloud hosting.

## ğŸ“„ License

Distributed under the [MIT License](LICENSE).

## ğŸ‘¤ Author

* GitHub: [@RucoH](https://github.com/RucoH)
* Live Site: [https://rucoh.github.io/](https://rucoh.github.io/)
